# ğŸ“˜ AI-Powered PDF Q&A System

A lightweight, local-first AI-powered Question Answering (Q&A) system over PDF documents using embeddings, FAISS, and open-source language models.

---

## ğŸš€ Tech Stack Used

| Component        | Technology                          |
|------------------|--------------------------------------|
| **Frontend/UI**  | Streamlit                           |
| **PDF Parsing**  | `pdfplumber`                        |
| **Embeddings**   | `sentence-transformers` (`all-MiniLM-L6-v2`) |
| **Vector Store** | FAISS (in-memory)                   |
| **LLM Backend**  | `llama-cpp-python` + Mistral 7B Instruct GGUF |
| **Voice Input**  | `speech_recognition` (Google Speech-to-Text) |

---

## ğŸ“‚ Folder Structure

```
â”œâ”€â”€ app.py
â”œâ”€â”€ ingestion.py
â”œâ”€â”€ embedder.py
â”œâ”€â”€ vector_store.py
â”œâ”€â”€ qa_engine.py
â”œâ”€â”€ audio_input.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mistral-7b-instruct-v0.1.Q4_K_M.gguf
â”œâ”€â”€ static/
â”‚   â””â”€â”€ uploaded_pdfs/
â”œâ”€â”€ sample_pdfs/
â”‚   â””â”€â”€ Wireshark_DNS_Help-1.pdf
â”œâ”€â”€ requirements.txt
```

---

## âš™ï¸ How to Run Locally

1ï¸âƒ£ **Clone the Repository:**

```bash
git clone <your-repo-link>
cd <repo-folder>
```

2ï¸âƒ£ **Set Up Virtual Environment (Optional but Recommended):**

```bash
python -m venv venv
venv\Scripts\activate  # Windows
```

3ï¸âƒ£ **Install Dependencies:**

```bash
pip install -r requirements.txt
```

ğŸ”— **Important:** Install `llama-cpp-python` properly:

```bash
pip install llama-cpp-python
```

âœ… Make sure you have the **Mistral GGUF model** downloaded and placed inside the `models/` folder as:

```
models/mistral-7b-instruct-v0.1.Q4_K_M.gguf
```

4ï¸âƒ£ **Run the App:**

```bash
streamlit run app.py
```

5ï¸âƒ£ **Test:**
- Upload any PDF (sample PDF `Wireshark_DNS_Help-1` provided)
- Ask a question via text or click **Voice Query** to speak
- Answers + sources will appear below

---

## âš ï¸ Known Issues / Limitations

- ğŸ”„ **LLM Inference Speed:** Running Mistral-7B locally may be slow on lower-end devices.
- ğŸ§  **Answer Quality:** Sometimes answers may be incomplete or inaccurate if context chunks are poor.
- ğŸ“„ **Source Highlighting:** Partial; shows source snippets but doesn't highlight exact lines in PDF.
- ğŸ”Š **Voice Input Errors:** Speech-to-text may occasionally fail; fall back to text input.
- ğŸ’¾ **FAISS Persistence:** Current FAISS index is rebuilt every time â€” no long-term persistence between runs.

---

âœ… Tested on:
- Windows 10/11
- Python 3.10+
- Streamlit 1.34+
- llama-cpp-python 0.2+

---

ğŸ‘‰ For best performance:
- Use smaller Mistral GGUF models (Q4_K_M recommended)
- Avoid very large PDFs (>200 pages) without sufficient system RAM.

---

Thank you ğŸ™

